
视频讲述了NeurIPS 2025一篇关于Agent缓存技术的论文分享，介绍了现有Agent缓存方法的局限、提出的Agentic Plan Caching（APC）方法及其实验效果等内容，具体如下：
- **论文背景与研究目标**：当前Agent工作中频繁调用API或运行模型，存在算力和金钱消耗高的问题，研究旨在通过缓存可复用操作，减少后续类似问题的重复计算，降低消耗。
- **现有主流缓存方法及局限**：一是Context Caching，依赖模型KV矩阵存储固定输入，与模型架构高度绑定无法迁移，且需完全匹配才能复用；二是语义Caching，存储输入输出对，仅适用于问答场景，在Agent多场景下泛化能力差，相似输入可能对应完全不同输出。
- **APC方法框架**：拿到用户问题后，先用小模型提取关键词，到缓存中匹配。未匹配到（Cache Miss）时，按传统流程调用大模型规划并执行，得到结果后用小模型提取关键词和概括性计划模板存入缓存；匹配到（Cache Hit）时，将模板和问题输入小模型生成计划，再执行迭代，无需调用大模型规划，节省消耗。
- **APC方法关键设计原因**：选择提取关键词匹配而非直接用query匹配，是因query精确匹配率低、抽象度差，语义相似度匹配易有误差且需调阈值；采用关键词精确匹配，避免模糊匹配调阈值复杂和额外计算量问题；仅缓存计划模板而非完整执行历史，因小模型处理长上下文能力有限，简洁模板更利于其规划。
- **实验部分结果**：展示了不同方法的成本与准确率对比，APC方法在节省约一半成本的同时，保持90%以上准确率，接近全用大模型的准确率；APC在Cache Miss和Cache Hit时准确率差异小，而现有方法差异大；随着测试query推进，APC的命中率提升，成本增长减缓，且离线预热缓存能进一步降低成本和延迟，提升效果。



<img width="1221" height="781" alt="image" src="https://github.com/user-attachments/assets/50bbdf06-faff-4418-b08d-0fff86d7ef8a" />



<img width="1259" height="744" alt="image" src="https://github.com/user-attachments/assets/4d56b0eb-626f-43bf-bac8-ea5ea6602a49" />
